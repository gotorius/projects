{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2359b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------------------\n",
    "# Dataset 定義\n",
    "# --------------------------\n",
    "class PCamDataset(Dataset):\n",
    "    def __init__(self, h5_x_path, h5_y_path=None, transform=None):\n",
    "        self.x_path = h5_x_path\n",
    "        self.y_path = h5_y_path\n",
    "        self.transform = transform\n",
    "        self.has_labels = h5_y_path is not None\n",
    "\n",
    "        with h5py.File(h5_x_path, 'r') as x_file:\n",
    "            self.length = len(x_file['x'])\n",
    "\n",
    "        if self.has_labels:\n",
    "            with h5py.File(h5_y_path, 'r') as y_file:\n",
    "                self.labels = y_file['y'][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.x_path, 'r') as x_file:\n",
    "            image = x_file['x'][idx].astype(np.uint8)\n",
    "\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = self.labels[idx].item()\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# パスと設定\n",
    "# --------------------------\n",
    "TRAIN_X = 'camelyonpatch_level_2_split_train_x.h5'\n",
    "TRAIN_Y = 'camelyonpatch_level_2_split_train_y.h5'\n",
    "VAL_X   = 'valid_x_uncompressed.h5'\n",
    "VAL_Y   = 'valid_y_uncompressed.h5'\n",
    "TEST_X  = 'camelyonpatch_level_2_split_test_x.h5'\n",
    "TEST_Y  = 'camelyonpatch_level_2_split_test_y.h5'\n",
    "\n",
    "mean = [0.702, 0.538, 0.597]\n",
    "std = [0.144, 0.181, 0.177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4180a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96, scale=(0.6, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.05),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomApply([transforms.RandomSolarize(threshold=0.5, p=0.3)], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59223e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Dataloader\n",
    "# --------------------------\n",
    "batch_size = 128\n",
    "train_ds = PCamDataset(TRAIN_X, TRAIN_Y, transform=train_transform)\n",
    "val_ds   = PCamDataset(VAL_X, VAL_Y, transform=eval_transform)\n",
    "test_ds  = PCamDataset(TEST_X, TEST_Y, transform=eval_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ea187c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm  # pip install timm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=1)\n",
    "# または\n",
    "# model = timm.create_model('convnext_small', pretrained=True, num_classes=1)\n",
    "\n",
    "# カスタムヘッドの追加\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98f83f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "criterion = FocalLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02827541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,  # 最初の周期のエポック数\n",
    "    T_mult=2, # 周期の倍率\n",
    "    eta_min=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f68be9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_predict(model, image, n_aug=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 基本変換\n",
    "        base_tf = eval_transform\n",
    "        \n",
    "        # TTA変換リスト\n",
    "        tta_transforms = [\n",
    "            base_tf,\n",
    "            transforms.Compose([base_tf, transforms.RandomHorizontalFlip(p=1.0)]),\n",
    "            transforms.Compose([base_tf, transforms.RandomVerticalFlip(p=1.0)]),\n",
    "            transforms.Compose([base_tf, transforms.RandomRotation(30)]),\n",
    "            transforms.Compose([base_tf, transforms.ColorJitter(brightness=0.2, contrast=0.2)])\n",
    "        ]\n",
    "        \n",
    "        outputs = []\n",
    "        for tf in tta_transforms[:n_aug]:\n",
    "            augmented = tf(image)\n",
    "            output = model(augmented.unsqueeze(0).to(device))\n",
    "            outputs.append(torch.sigmoid(output).cpu())\n",
    "            \n",
    "        return torch.stack(outputs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b6ffda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for imgs, labels in progress_bar:\n",
    "        imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        \n",
    "        # MixUp データ拡張\n",
    "        if np.random.rand() < 0.5:\n",
    "            lam = np.random.beta(0.4, 0.4)\n",
    "            rand_index = torch.randperm(imgs.size(0))\n",
    "            labels_a = labels\n",
    "            labels_b = labels[rand_index]\n",
    "            \n",
    "            mixed_x = lam * imgs + (1 - lam) * imgs[rand_index]\n",
    "            outputs = model(mixed_x)\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 勾配クリッピング\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21f74f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# scikit-learnが使えない場合の代替評価関数\n",
    "def calculate_metrics(outputs, labels):\n",
    "    outputs = torch.sigmoid(outputs).cpu().numpy()\n",
    "    preds = (outputs > 0.5).astype(int)\n",
    "    labels = labels.cpu().numpy()\n",
    "    \n",
    "    # 簡易版Accuracy計算\n",
    "    acc = (preds == labels).mean()\n",
    "    \n",
    "    # 簡易版AUC計算（scikit-learnなし）\n",
    "    pos_prob = outputs[labels == 1]\n",
    "    neg_prob = outputs[labels == 0]\n",
    "    auc = (pos_prob[:, None] > neg_prob).mean() if len(pos_prob) > 0 and len(neg_prob) > 0 else 0.5\n",
    "    \n",
    "    # 簡易版F1計算\n",
    "    tp = ((preds == 1) & (labels == 1)).sum()\n",
    "    fp = ((preds == 1) & (labels == 0)).sum()\n",
    "    fn = ((preds == 0) & (labels == 1)).sum()\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "    \n",
    "    return acc, auc, f1\n",
    "\n",
    "# ...（その他のコードは以前と同じ）...\n",
    "\n",
    "def evaluate(loader, split='Val'):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=f\"Evaluating {split}\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long().squeeze()\n",
    "            \n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    # メトリクス計算\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    acc, auc, f1 = calculate_metrics(all_outputs, all_labels)\n",
    "    \n",
    "    print(f\"{split} Metrics - Acc: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# ...（その他のコードは変更なし）..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b98a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_tta(loader, split='Test'):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=f\"TTA {split}\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            batch_preds = []\n",
    "            \n",
    "            for img in imgs:\n",
    "                img_pil = transforms.ToPILImage()(img.cpu())\n",
    "                pred = tta_predict(model, img_pil)\n",
    "                batch_preds.append(pred)\n",
    "            \n",
    "            preds = (torch.stack(batch_preds) > 0.5).long().squeeze()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    acc = correct / total\n",
    "    print(f\"TTA {split} Accuracy: {acc * 100:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d33c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2048/2048 [05:53<00:00,  5.80it/s, loss=0.0305, lr=1.01e-5]\n",
      "Evaluating Val: 100%|██████████| 256/256 [00:11<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Metrics - Acc: 50.01% | AUC: 0.8358 | F1: 0.4451\n",
      "New best model saved. Val Acc: 50.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  13%|█▎        | 259/2048 [00:42<04:52,  6.12it/s, loss=0.0322, lr=2.68e-6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTTA Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtta_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m patience = \u001b[32m7\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     train_loss = train_one_epoch(epoch)\n\u001b[32m     10\u001b[39m     val_acc = evaluate(val_loader, \u001b[33m'\u001b[39m\u001b[33mVal\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_acc > best_val_acc:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(epoch)\u001b[39m\n\u001b[32m      3\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m      4\u001b[39m progress_bar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[32m      7\u001b[39m     imgs, labels = imgs.to(device), labels.float().unsqueeze(\u001b[32m1\u001b[39m).to(device)\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# MixUp データ拡張\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:1191\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1189\u001b[39m dt = cur_t - last_print_t\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dt >= mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t >= min_start_t:\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m     \u001b[38;5;28mself\u001b[39m.update(n - last_print_n)\n\u001b[32m   1192\u001b[39m     last_print_n = \u001b[38;5;28mself\u001b[39m.last_print_n\n\u001b[32m   1193\u001b[39m     last_print_t = \u001b[38;5;28mself\u001b[39m.last_print_t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:1242\u001b[39m, in \u001b[36mtqdm.update\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dn(dn)\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dt(dt)\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m \u001b[38;5;28mself\u001b[39m.refresh(lock_args=\u001b[38;5;28mself\u001b[39m.lock_args)\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dynamic_miniters:\n\u001b[32m   1244\u001b[39m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maxinterval \u001b[38;5;129;01mand\u001b[39;00m dt >= \u001b[38;5;28mself\u001b[39m.maxinterval:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:1347\u001b[39m, in \u001b[36mtqdm.refresh\u001b[39m\u001b[34m(self, nolock, lock_args)\u001b[39m\n\u001b[32m   1345\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1346\u001b[39m         \u001b[38;5;28mself\u001b[39m._lock.acquire()\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m \u001b[38;5;28mself\u001b[39m.display()\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:1495\u001b[39m, in \u001b[36mtqdm.display\u001b[39m\u001b[34m(self, msg, pos)\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(pos)\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m \u001b[38;5;28mself\u001b[39m.sp(\u001b[38;5;28mself\u001b[39m.\u001b[34m__str__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[32m   1496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1497\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(-pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:459\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.print_status\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_status\u001b[39m(s):\n\u001b[32m    458\u001b[39m     len_s = disp_len(s)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     fp_write(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m + s + (\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m * \u001b[38;5;28mmax\u001b[39m(last_len[\u001b[32m0\u001b[39m] - len_s, \u001b[32m0\u001b[39m)))\n\u001b[32m    460\u001b[39m     last_len[\u001b[32m0\u001b[39m] = len_s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/std.py:453\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.fp_write\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfp_write\u001b[39m(s):\n\u001b[32m    452\u001b[39m     fp.write(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     fp_flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/utils.py:196\u001b[39m, in \u001b[36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m e.errno != \u001b[32m5\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/ipykernel/iostream.py:604\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[32m    594\u001b[39m \n\u001b[32m    595\u001b[39m \u001b[33;03msend will happen in the background thread\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread\n\u001b[32m    599\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pub_thread.thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    602\u001b[39m ):\n\u001b[32m    603\u001b[39m     \u001b[38;5;66;03m# request flush on the background thread\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(\u001b[38;5;28mself\u001b[39m._flush)\n\u001b[32m    605\u001b[39m     \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[32m    606\u001b[39m     evt = threading.Event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/ipykernel/iostream.py:267\u001b[39m, in \u001b[36mIOPubThread.schedule\u001b[39m\u001b[34m(self, f)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m._events.append(f)\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28mself\u001b[39m._event_pipe.send(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     f()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/zmq/sugar/socket.py:701\u001b[39m, in \u001b[36mSocket.send\u001b[39m\u001b[34m(self, data, flags, copy, track, routing_id, group)\u001b[39m\n\u001b[32m    694\u001b[39m         data = zmq.Frame(\n\u001b[32m    695\u001b[39m             data,\n\u001b[32m    696\u001b[39m             track=track,\n\u001b[32m    697\u001b[39m             copy=copy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    698\u001b[39m             copy_threshold=\u001b[38;5;28mself\u001b[39m.copy_threshold,\n\u001b[32m    699\u001b[39m         )\n\u001b[32m    700\u001b[39m     data.group = group\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().send(data, flags=flags, copy=copy, track=track)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1092\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1140\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1332\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._send_copy\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:160\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._check_rc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# メイン訓練ループ\n",
    "# --------------------------\n",
    "def main():\n",
    "    best_val_acc = 0\n",
    "    early_stop_counter = 0\n",
    "    patience = 7\n",
    "    \n",
    "    for epoch in range(1, 50):\n",
    "        train_loss = train_one_epoch(epoch)\n",
    "        val_acc = evaluate(val_loader, 'Val')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            early_stop_counter = 0\n",
    "            print(f\"New best model saved. Val Acc: {val_acc*100:.2f}%\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # 最終評価\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    test_acc = evaluate(test_loader, 'Test')\n",
    "    tta_acc = evaluate_with_tta(test_loader)\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Standard Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"TTA Test Accuracy: {tta_acc*100:.2f}%\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
