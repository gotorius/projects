{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    super().__init__()\n",
    "    self.embed = nn.Sequential(\n",
    "        GaussianFourierProjection(embed_dim=embed_dim),\n",
    "        nn.Linear(embed_dim, embed_dim)\n",
    "    )\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, channels[0], 3, stride=1, padding=1, bias=False)  # 入力チャネル変更\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2]+channels[2], channels[1], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1]+channels[1], channels[0], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0]+channels[0], 3, 3, stride=1, padding=1)  # 出力チャネル変更\n",
    "\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "  def forward(self, x, t): \n",
    "    embed = self.act(self.embed(t))\n",
    "    h1 = self.act(self.gnorm1(self.conv1(x) + self.dense1(embed)))\n",
    "    h2 = self.act(self.gnorm2(self.conv2(h1) + self.dense2(embed)))\n",
    "    h3 = self.act(self.gnorm3(self.conv3(h2) + self.dense3(embed)))\n",
    "    h4 = self.act(self.gnorm4(self.conv4(h3) + self.dense4(embed)))\n",
    "\n",
    "    h = self.act(self.tgnorm4(self.tconv4(h4) + self.dense5(embed)))\n",
    "    h = self.act(self.tgnorm3(self.tconv3(torch.cat([h, h3], dim=1)) + self.dense6(embed)))\n",
    "    h = self.act(self.tgnorm2(self.tconv2(torch.cat([h, h2], dim=1)) + self.dense7(embed)))\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05af332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# モデル・関数の事前定義（省略していた場合は必要）\n",
    "# → ScoreNet, marginal_prob_std_fn, loss_fn 等は定義済みと仮定\n",
    "# -------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import functools\n",
    "import h5py\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "class PCamDataset_k(Dataset):\n",
    "    def __init__(self, x_path, y_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.x_h5 = h5py.File(x_path, 'r')\n",
    "        self.y_h5 = h5py.File(y_path, 'r')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_h5['x'].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.x_h5['x'][idx]\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = np.concatenate([img]*3, axis=2)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.y_h5['y'][idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# ----------- パラメータ -------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_epochs = 500\n",
    "batch_size = 16\n",
    "lr = 2e-4\n",
    "sigma = 10.0\n",
    "marginal_prob_std_fn = functools.partial(lambda t, sigma: torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma)), sigma=sigma)\n",
    "\n",
    "# ----------- モデルとデータ -------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),  # 小さめの回転\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # 軽微な色変化\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = PCamDataset_k(\n",
    "    '/home/gotou/Medical/camelyonpatch_level_2_split_train_x.h5',\n",
    "    '/home/gotou/Medical/camelyonpatch_level_2_split_train_y.h5',\n",
    "    transform=transform\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "score_model = ScoreNet(marginal_prob_std=marginal_prob_std_fn).to(device)\n",
    "optimizer = Adam(score_model.parameters(), lr=lr, betas=(0.9, 0.99))\n",
    "best_loss = 1000\n",
    "\n",
    "\n",
    "# ----------- 損失関数 -------------\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "    z = torch.randn_like(x)\n",
    "    std = marginal_prob_std(random_t)\n",
    "    perturbed_x = x + z * std[:, None, None, None]\n",
    "    score = model(perturbed_x, random_t)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss\n",
    "\n",
    "# ----------- 学習ループ -------------\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "tqdm_epoch = tqdm.trange(n_epochs, mininterval=1.0)\n",
    "for epoch in tqdm_epoch:\n",
    "    avg_loss = 0.\n",
    "    num_items = 0\n",
    "    score_model.train()\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        x = x.to(device)\n",
    "        loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() * x.shape[0]\n",
    "        num_items += x.shape[0]\n",
    "        if i >= 256:  # 必要なら短縮可\n",
    "            break\n",
    "\n",
    "    tqdm_epoch.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss / num_items:.4f}\")\n",
    "\n",
    "    if avg_loss / num_items < best_loss:\n",
    "        best_loss = avg_loss / num_items\n",
    "        torch.save(score_model.state_dict(), 'checkpoints/best_model.pth')\n",
    "\n",
    "\n",
    "print(\" 学習完了\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ループがすべて終わった後にモデルを保存\n",
    "torch.save(score_model.state_dict(), 'checkpoints/final_model.pth')\n",
    "print(\"最終モデルを checkpoints/final_model.pth に保存しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
