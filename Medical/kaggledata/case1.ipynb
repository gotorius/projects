{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9c122b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6939420104026794\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "DATA_DIR = './'\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train')\n",
    "LABELS_CSV = os.path.join(DATA_DIR, 'train_labels.csv')\n",
    "\n",
    "# データセットクラス\n",
    "class PCamDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_csv, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.labels.iloc[idx, 0]\n",
    "        label = self.labels.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.tif\")\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 前処理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# データローダー\n",
    "train_dataset = PCamDataset(TRAIN_IMG_DIR, LABELS_CSV, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 簡単なCNNモデル\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 24 * 24, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 24 * 24)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x.squeeze()\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# 損失関数と最適化\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習ループ（1エポック例）\n",
    "for images, labels in train_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'loss: {loss.item()}')\n",
    "    break  # サンプルとして1バッチのみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f36683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gotou/miniconda3/envs/myenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gotou/miniconda3/envs/myenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6149500608444214\n",
      "05dcf7099d054b8af930253bbc2c3fb9055ac0a5.tif の予測値: 0.3388\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# ResNet50の転移学習モデル（出力1次元に変更）\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 1)\n",
    "model = resnet50.to(device)\n",
    "\n",
    "# 前処理（ResNet50用、3ch・224x224）\n",
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# データセット・ローダー（再定義）\n",
    "train_dataset_resnet = PCamDataset(TRAIN_IMG_DIR, LABELS_CSV, transform_resnet)\n",
    "train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=32, shuffle=True)\n",
    "\n",
    "# 損失関数と最適化\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 学習ループ（1バッチのみ例）\n",
    "for images, labels in train_loader_resnet:\n",
    "    images = images.to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images).squeeze()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'loss: {loss.item()}')\n",
    "    break  # サンプルとして1バッチのみ\n",
    "\n",
    "# 予測例（test画像の1枚）\n",
    "test_img_name = os.listdir(TEST_IMG_DIR)[0]\n",
    "test_img_path = os.path.join(TEST_IMG_DIR, test_img_name)\n",
    "test_img = Image.open(test_img_path)\n",
    "test_tensor = transform_resnet(test_img).unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(test_tensor)\n",
    "    pred = torch.sigmoid(output).item()\n",
    "    print(f'{test_img_name} の予測値: {pred:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fec966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gotou/miniconda3/envs/myenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gotou/miniconda3/envs/myenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1443\n",
      "Val Accuracy: 96.72%\n",
      "Epoch 2/5, Loss: 0.0883\n",
      "Val Accuracy: 95.65%\n",
      "Epoch 3/5, Loss: 0.0633\n",
      "Val Accuracy: 97.38%\n",
      "Epoch 4/5, Loss: 0.0444\n",
      "Val Accuracy: 97.35%\n",
      "Epoch 5/5, Loss: 0.0331\n",
      "Val Accuracy: 97.15%\n",
      "Test予測例: [0.9999980926513672, 2.3613171151737333e-07, 0.0028101117350161076, 0.7870376706123352, 0.002361058723181486]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels_df = pd.read_csv(LABELS_CSV)\n",
    "\n",
    "\n",
    "class PCamDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_df, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = labels_df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.labels.iloc[idx, 0]\n",
    "        label = self.labels.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.tif\")\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# train/val分割\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.1, random_state=42, stratify=labels_df['label'])\n",
    "\n",
    "train_dataset = PCamDataset(TRAIN_IMG_DIR, train_df, transform_resnet)\n",
    "val_dataset = PCamDataset(TRAIN_IMG_DIR, val_df, transform_resnet)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# ResNet50モデル\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 1)\n",
    "model = resnet50.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 学習ループ\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # 検証\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    print(f'Val Accuracy: {val_acc*100:.2f}%')\n",
    "\n",
    "# テストデータ予測\n",
    "test_img_names = os.listdir(TEST_IMG_DIR)\n",
    "test_preds = []\n",
    "model.eval()\n",
    "for img_name in test_img_names:\n",
    "    img_path = os.path.join(TEST_IMG_DIR, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    tensor = transform_resnet(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "        pred = torch.sigmoid(output).item()\n",
    "        test_preds.append(pred)\n",
    "print('Test予測例:', test_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7370a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csvを保存しました\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 予測結果をCSVに保存\n",
    "submission = pd.DataFrame({\n",
    "    'id': [os.path.splitext(name)[0] for name in test_img_names],\n",
    "    'label': test_preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('submission.csvを保存しました')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
